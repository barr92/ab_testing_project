{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Behavour and Sales Analysis\n",
    "\n",
    "We will now conduct a study using an AB test on the website sales funnel for a website application. Our objective is to comprehend the sequence of actions users undertake, including the various online events that occur. \n",
    "\n",
    "Furthermore, we will examine how users interact at each stage, identifying drop-off points, conversion times, retention rates, lifetime value, and the most popular events. In conclusion, we will conduct statistical tests to determine the performance of each test group and provide business recommendations based on our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries that we might need later on, including scipy for statistical testing\n",
    "# ploty for creating our funnel visualisation as well as matplotlib and season for distribution and frequancies\n",
    "# Pandas and Numpy will be out main libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from scipy import stats as st\n",
    "from statsmodels.stats import proportion\n",
    "import math as mth\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "import plotly.graph_objects as go\n",
    "import math as mth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "log_file = pd.read_csv(r\"/datasets/logs_exp_us.csv\", encoding='utf-8', sep='\\t')\n",
    "log_file.columns = ['event', 'user_id', 'timestamp', 'test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Rename the columns \n",
    "- Check for missing values and data types.\n",
    "- Add a date and time column and a separate column for dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time seems to be in the incorrect format, so we need to use pd.todatetime to convert\n",
    "print(pd.to_datetime(log_file['timestamp'], unit='s').loc[0])\n",
    "print(pd.to_datetime(log_file['timestamp'], unit='s').dt.month.loc[0])\n",
    "print(pd.to_datetime(log_file['timestamp'], unit='s').dt.weekday.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date feature looks correct so I will convert all now\n",
    "log_file['timestamp'] = pd.to_datetime(log_file['timestamp'], unit='s') \n",
    "log_file['weekday'] = log_file['timestamp'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file['date'] = pd.to_datetime(log_file['timestamp'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file['test_id'] = log_file['test_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file[log_file.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = log_file.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the duplicate values in the data in order to ensure they don't damage our final analysis.\n",
    "\n",
    "Based on the above grouped data we can understand the user flow on the website. It appears that Main Screen Appear is step 1 which has the most users, followed by Offers screen, then cart screen, payment screen is the 2nd the last stage and tutorial is the final converted step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the data\n",
    "\n",
    "#### Summary\n",
    "\n",
    "In the analysis, several key aspects of the log file have been addressed. Firstly, the total number of events and users, the average number of events and the correct data range has been established. A histogram plotting events against date and time has been created, this helped us to understand the date ranges by hour and day.\n",
    "\n",
    "The decision was made to focus on data from August 1st onwards to eliminate skewing effects and to ensure our data is consistent and complete. \n",
    "\n",
    "The resulting data period has been defined. The impact of excluding older data on events and users has been assessed. It was ensured that all three experimental groups are represented among users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many events and users are in the logs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_file.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table we can see that there are 243713 total events (5 unique types) and ther are about 243k sessions and 176k users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average events per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at events per user\n",
    "events_by_user=log_file.groupby(['user_id'])['event'].count().reset_index()\n",
    "events_by_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_by_user['event'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "axes[0].boxplot(events_by_user['event'])\n",
    "axes[0].set_title('Boxplot of events by user with outliers')\n",
    "axes[1].boxplot(events_by_user['event'],showfliers=False)\n",
    "axes[1].set_title('Boxplot of events by user without outliers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon visualising the above exploration, we can tell that our core dataset sits between 10 and 37 events per users and the average is 32 events per users. Anything above that is considered an outliers. Our main distrupters are considered as users who had more than 80 events records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Period Analysis\n",
    "\n",
    "#### Summary\n",
    "\n",
    "The time period analysis will feature a left-skewed histogram, indicated a concentration of data in the campaign's final weeks. The starting days exhibited low activity, most likely due to preparation, sampling and testing. \n",
    "\n",
    "This is why (as briefly touched on in the summary above) we will slice the data from the 1st August to the 7th August, resulting in 1.15% of the data being lost, which won't affect our analysis. Stringent checks detect no implicit or user ID duplicates, applying methods from the \"Making Business Decisions\" project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = log_file['timestamp'].min()\n",
    "last_date = log_file['timestamp'].max()\n",
    "print(\"The time period of the date is from\",first_date, \"to\", last_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "# Distribution by dates\n",
    "axes[0].hist(log_file['timestamp'], bins=100, edgecolor='black')\n",
    "axes[0].set_title('date distribution all dates')\n",
    "axes[0].set_xlabel('date')\n",
    "axes[0].set_ylabel('freqancy')\n",
    "axes[0].tick_params(axis='x', labelrotation=65)\n",
    "\n",
    "# Distribution by day and hour\n",
    "axes[1].hist(log_file[(log_file['timestamp']>='2019-07-31')&(log_file['timestamp']<='2019-08-02')]['timestamp'], \n",
    "         color='red', edgecolor='black', alpha=0.5, bins=100)\n",
    "axes[1].set_title('date distribution by hours')\n",
    "axes[1].set_xlabel('Date and Hours')\n",
    "axes[1].set_ylabel('frequancy')\n",
    "axes[1].tick_params(axis='x', labelrotation=65)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values from before 1st August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_records = log_file[log_file['timestamp'] < '2019-08-01']\n",
    "missing_values = len(old_records) / len(log_file)*100\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values before the 1st August made up 1.15% percent of our dataset. Below you will be able to observe the number of events and users during this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_users = old_records.groupby('user_id')['event'].count().reset_index()\n",
    "old_users.columns=['user','event']\n",
    "\n",
    "fix, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "axes[0].boxplot(old_users['event'])\n",
    "axes[0].set_title('Old Records before 1st August')\n",
    "axes[1].hist(old_records['timestamp'], edgecolor='black')\n",
    "axes[1].set_title('Histogram of old records')\n",
    "\n",
    "print(old_users['event'].describe())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the records before the 1st of August, there was a very low frequancy as we saw in the histograms above, thereforem I have presented a box plot of the old records to show whether there are sufficient records. However, the frequancy is increasing on the 31st July, therefore, it will be worth increasing our data range to include the last day in July and disregard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_records['event'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Sample Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.groupby('test_id')['user_id'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering with our new dates\n",
    "log_fil = log_file[(log_file['timestamp']>='2019-07-31')]\n",
    "log_fil.groupby('test_id')['user_id'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_data = len(log_fil) / len(log_file)\n",
    "print(\"After filtering by date we are left with {:.2%} in our AB testing dataframe.\".format(percent_of_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for implicit duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_groups = log_file.groupby('user_id').agg({'test_id': 'nunique'}).reset_index()\n",
    "both_groups.columns = ['user_id', 'test_id']\n",
    "both_groups = both_groups[both_groups['test_id'] != 1]\n",
    "duplicate_visitors = both_groups['user_id'].to_list()\n",
    "print(duplicate_visitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding implicit duplicates, which in this case refer to users who may have been placed in different groups, we don't have any, so we can continue with our analysis without this concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the event funnel in detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file['test_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.groupby('event')['user_id'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.groupby('event')['user_id'].nunique().sort_values(ascending=False)/log_file.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above groupby helps us to understand the flow of the product funnel, with the highest proportion of events firing on the home page screen and there being the highest amount of dropoffs at the product page, shopping cart and final purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the funnel tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split up the tests by counting users, events, events per user and then take the percentage dropoffs.\n",
    "Once, we've creating a table for each test we will append them into one dataframe and create a funnel chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = log_file[log_file['test_id']=='246'].groupby(['test_id','event']).agg({'user_id': ['size','nunique']}).reset_index()\n",
    "test_2 = log_file[log_file['test_id']=='247'].groupby(['test_id','event']).agg({'user_id': ['size','nunique']}).reset_index()\n",
    "test_3 = log_file[log_file['test_id']=='248'].groupby(['test_id','event']).agg({'user_id': ['size','nunique']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.columns = ['test_id','event', 'events', 'users']\n",
    "test_2.columns = ['test_id','event', 'events', 'users']\n",
    "test_3.columns = ['test_id','event', 'events', 'users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1.sort_values(by='users', ascending=False)\n",
    "test_2 = test_2.sort_values(by='users', ascending=False)\n",
    "test_3 = test_3.sort_values(by='users', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1['event_per_user'] = test_1['events'] / test_1['users']\n",
    "test_2['event_per_user'] = test_2['events'] / test_2['users']\n",
    "test_3['event_per_user'] = test_3['events'] / test_3['users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1['pct_change_users']= test_1['users'].pct_change(periods=1, fill_method=None)\n",
    "test_2['pct_change_users']= test_2['users'].pct_change(periods=1, fill_method=None)\n",
    "test_3['pct_change_users']= test_2['users'].pct_change(periods=1, fill_method=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the Tutorial\n",
    "\n",
    "The tutorial is not a compulory event. Therefore, does not need to be displayed in the funnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1[test_1['event']!='Tutorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = test_2[test_2['event']!='Tutorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = test_3[test_3['event']!='Tutorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_funnel = pd.concat([test_1, test_2, test_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Funnel(\n",
    "    y=test_funnel['event'],\n",
    "    x= test_funnel['users'],\n",
    "    textinfo =\"value+percent initial+percent previous\",\n",
    "    hoverinfo = \"percent initial+percent previous\",\n",
    "))\n",
    "   \n",
    "fig.update_layout(title=\"Purchase Funnel Stages with Percentage Dropoff\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The above table and visualisation displays the drop offs in users as they go through each stage of the funnel. \n",
    "\n",
    "The offer screen had the most dropoffs at the second stage in the funnel, with around 40% of the homepage users staying only across all groups. Following from them a higher proportion of users went through the cart and almost all of the converted at the payment step, which shows positive signs for our campaign profitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What share of users make the entire journey from their first event to payment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first and final event of the funnel\n",
    "log_fil[log_fil['event'].isin(['MainScreenAppear','PaymentScreenSuccessful'])].groupby('event')['user_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Main screen is the start and the payment screen is the final conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now find out the number of unique users at each stage by doing the nunique function instead of counting all.\n",
    "user_journeys = pd.pivot_table(log_fil, index='test_id',columns='event',values='user_id', aggfunc=['nunique'])\n",
    "user_journeys['completed'] = user_journeys[('nunique','PaymentScreenSuccessful')] / user_journeys[('nunique','MainScreenAppear')]\n",
    "user_journeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion/Summary\n",
    "\n",
    "- There were 49% of the users who completed the course from the first event for test from 246.\n",
    "- There was a -3% difference for group 247 with 46% proporotion of users completing the event funnel from step 1.\n",
    "- There was a 1% difference between 246 and 248 as there was a 47% proportion of users completing the event funnel form step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long did it take from MainScreenAppear to PaymentScreenSuccessful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now determine how long it took the user to purchase to purchase. We'll first need to take out the tutorial step as this appears to be optional and could constitute a video on the final step or the homepage. \n",
    "\n",
    "Then we will calculate the first date for each event and calculate the difference between each of the two key steps Main Screen and Purchase Screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all of the first timestamps for each of the events.\n",
    "first_timestamp = pd.pivot_table(log_fil[log_fil['event'] != 'Tutorial'], \n",
    "                                 index='user_id', columns='event', values='timestamp', aggfunc='min').reset_index()\n",
    "first_timestamp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_elapsed = (first_timestamp['PaymentScreenSuccessful'] - first_timestamp['OffersScreenAppear'])\n",
    "time_elapsed.sort_values().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the time elapsed to a column\n",
    "first_timestamp['time_elapsed'] = (first_timestamp['PaymentScreenSuccessful'] - first_timestamp['OffersScreenAppear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numerical columns for the data\n",
    "first_timestamp['time_elapsed'] = first_timestamp['time_elapsed'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_timestamp[first_timestamp['time_elapsed'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_timestamp[first_timestamp['user_id'] == 76430713684339660]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative times could be due to users who visited the main screen after they visited the payment screen due to openning in a new tab, or being on the payment screen for a long period of time. Therefore, we will remove the negative values from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_times = first_timestamp[first_timestamp['time_elapsed'] < 0]\n",
    "first_timestamp.drop(negative_times.index, inplace=True)\n",
    "first_timestamp['time_elapsed'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_timestamp['time_elapsed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the distribution from the pivot table.\n",
    "plt.hist(first_timestamp['time_elapsed'], bins=10)\n",
    "plt.title('time until conversion')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('frequancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of our users took less than a day to complete a purchase with a small variety of users taking up to a full day before making a purchase on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the results of the experiment (A/A1, A/B, A1/B, AA1/B)\n",
    "\n",
    "We will now perform a series of satistical tests to determine which group outperformed which.\n",
    "\n",
    "We will be testing the statistical significance between the test group (248: with new fonts) and both of our control (as we now know there will be no difference between the test.)\n",
    "\n",
    "Here we will conduct 4 tests:\n",
    "\n",
    "- 246 vs 247 (control groups A/A1)\n",
    "- 246 vs 248 (A/B)\n",
    "- 247 vs 248 (A1/B)\n",
    "- 246+247 vs 248 (AA1/)\n",
    "\n",
    "For the test, we will look at the following hypothesis, for each event and test group:\n",
    "\n",
    "- H0: There was no statistical difference between the two groups\n",
    "- H1: There was a clear difference between the events of the groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the unique users per test group\n",
    "- Firstly, let's take thew unique users from our three different groups.\n",
    "- I will use test_id as the index and do a nunique.\n",
    "- This will give us our trials which we will call in our z_test function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_user_id = log_fil.groupby('test_id').agg({'user_id':'nunique'}).reset_index()\n",
    "nu_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the unique users as they pass through the funnel\n",
    "- The below pivot table gives us the unique users per event. \n",
    "- This gives us our successes that we will call into the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funnel=(log_fil.pivot_table(index='event', columns='test_id', values='user_id', aggfunc='nunique')\n",
    "        .reset_index()\n",
    "        .query('event !=\"Tutorial\"'))\n",
    "funnel['total'] = funnel['246']+funnel['247']+funnel['248']\n",
    "funnel=funnel.sort_values(by='total', ascending=False)\n",
    "funnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z Test Function\n",
    "\n",
    "<b>Step 1</b>\n",
    "- We add the parameters: trials (total unique users per group), column1 (represents the first test group from the successes pivot) and column2 (repesents the second column from the successes pivot)\n",
    "\n",
    "<b>The Loop:</b>\n",
    "- We loop over the each event and take the values for based on our chosen test groups.\n",
    "- then we will calculate the proportions of successes to trials for both test groups.\n",
    "\n",
    "<b>Step 3:</b>\n",
    "- We print here the values for each event from the pivot alongside the unique users.\n",
    "\n",
    "<b>Step 4:</b>\n",
    "\n",
    "Combined data: \n",
    "- The next step is to sum up both trials and successes and take the proportion.\n",
    "\n",
    "Statistical test:\n",
    "- Differences tells us how much the groups differ from each other (p1 - p2), Taking the difference between the proportions\n",
    "- p_compinbed helps us to measure the variability in the data\n",
    "- Calculate the Z Value tells us how many standard deviations the difference between the groups is from what you would expect. Then when we print the results, if the z_value is larg than there is a statisical significance.\n",
    "\n",
    "Output:\n",
    "- We will then print whether or not the pvalue is less than the alpha and whether we reject the null hypothesis or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def z_test(array, trials, column1, column2):\n",
    "    for i in range(0, 4):\n",
    "        successes = np.array([array.loc[i, column1], array.loc[i, column2]])        \n",
    "        p1 = successes[0]/trials[0]        \n",
    "        p2 = successes[1]/trials[1]\n",
    "        \n",
    "        # \n",
    "        print(successes[0], successes[1],trials[0], trials[1])\n",
    "        \n",
    "        # The next step is to sum up and take the proportion from all groups\n",
    "        p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])       \n",
    "        difference = p1 - p2     \n",
    "        # Assess the statisticual significance using the z_value statistical function\n",
    "        z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1/trials[0] + 1/trials[1]))       \n",
    "        distr = stats.norm(0, 1)        \n",
    "        p_value = (1 - distr.cdf(abs(z_value))) * 2   \n",
    "        alpha = 0.05 \n",
    "        print('{} p-value: {}'.format(funnel['event'][i], p_value))\n",
    "        if p_value < alpha:\n",
    "            print('We reject the null hypothesis: There was a clear difference between the successful events of the groups')\n",
    "        else:\n",
    "            print('There was no statistical difference between the success rate of the two groups')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A/A1 test - The control groups\n",
    "\n",
    "From the results below, we know that the main screen was the most popular event and the statistical significance between the groups accross all the events was insignificant. This was exactly what the product and marketing expected, which shows that both groups are suitable for comparision against our test group where the team adjusted the fonts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The control group test.#А/А1\n",
    "trials = np.array([nu_user_id.loc[0, 'user_id'], nu_user_id.loc[1, 'user_id']])\n",
    "z_test(funnel, trials, '246','247')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The A/B (control group 1 vs. test group)\n",
    "\n",
    "From the results below, we can see that there was know significant difference between 3 out of 4 events, which the home page having more events. Therefore, suggesting that for the test group there were slightly more visitors entering the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The control group 2 against the altered fonts test. (A/B)\n",
    "trials = np.array([nu_user_id.loc[0, 'user_id'], nu_user_id.loc[1, 'user_id']])\n",
    "z_test(funnel, trials, '246', '248')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The A1/B test (control group 2 vs. test group) \n",
    "\n",
    "Like the above results, we can also see that there was a statistical significance between the events fired on the homepage for the test group than the control groups, which resulted in their being a statistical significance for these events. Therefore, it could have been that the marketing campaigns teams increased the budget or changed their optimisation for test group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the results of the control group 247 and group 248.\n",
    "trials = np.array([nu_user_id.loc[0, 'user_id'], nu_user_id.loc[1, 'user_id']])\n",
    "z_test(funnel, trials, '247','248')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AA1/B test: Statistical significance between both groups and the test group\n",
    "\n",
    "Despite, what we said above, when we combined both control groups for the AA1/B test, there is no statistical significance between the test group and control groups. Therefore, we can say that there was no bias between the campaign optimisation for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_a_aa1 = np.array([nu_user_id.loc[0, 'user_id'] + nu_user_id.loc[1, 'user_id'], nu_user_id.loc[2, 'user_id']])\n",
    "funnel['AA1'] = funnel['246'] + funnel['247']\n",
    "z_test(funnel, trials_a_aa1, 'AA1', '248')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- Firstly, we filtered our core dataset to cut out the campaign dates where the IT and Development teams were testings the application (after 31st July, when traffic started). These only turned into a 1% loss of data so it will have no affect on our analysis.\n",
    "- Our outliers in the data, showed users interactiving and exceeding over 80 events. Suggesting that there was a high bounce rate and not enough users completion meaningful actions on the website. \n",
    "- The core data was without outliers was users with 10 to 37 events\n",
    "- There were no duplicates, problems with missing values and no implicit duplicates (users in more than one group)\n",
    "- There was no statistical significance between the control groups and this is what we had expected to see to ensure there is no bias\n",
    "- There was also only a statistical significance between the ho0me page events in both the control groups and the test group. Possibly due to an increased number of visitors to the new test group.\n",
    "\n",
    "When we compare the funnel, we noticed that there was a:\n",
    "- There were 49% of the users who completed the course from the first event for test from 246.\n",
    "- There was a -3% difference for group 247 with 46% proporotion of users completing the event funnel from step 1.\n",
    "- There was a 1% difference between 246 and 248 as there was a 47% proportion of users completing the event funnel form step 1.\n",
    "\n",
    "The conversion rate for each test group was stable and the majority of the users who visiting the product offering went to the cart page and continued to purchase. 90% of the users went from the cart to complete the payment, meaning that there was a cart abandonment rate of 10%.\n",
    "\n",
    "\n",
    "### Business Recommendations\n",
    "\n",
    "- We need to focus on optimising our user engagement to ensure there's no more than 10-37 events committed during a session.\n",
    "- Focus on improving the calls to action on the home page to drive more traffic to product offerings.\n",
    "- There is no need to consider font changes as they don't impact user behavior enough to warrant the hours of work.\n",
    "- Making too many drastic changes may damage the user experience and reduce our online success rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "557.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
